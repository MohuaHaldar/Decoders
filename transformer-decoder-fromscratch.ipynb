{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31286,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Description\n\nImplemented a Transformer decoder block manually\n\nUsed dummy data to understand:\n\nMasked Multi-Head Attention\n\nLayer Normalization\n\nResidual Connections\n\nFeed Forward Network","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport random, math\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T05:18:12.996937Z","iopub.execute_input":"2026-02-21T05:18:12.997277Z","iopub.status.idle":"2026-02-21T05:18:13.002469Z","shell.execute_reply.started":"2026-02-21T05:18:12.997248Z","shell.execute_reply":"2026-02-21T05:18:13.001500Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T05:18:13.005753Z","iopub.execute_input":"2026-02-21T05:18:13.006084Z","iopub.status.idle":"2026-02-21T05:18:13.027448Z","shell.execute_reply.started":"2026-02-21T05:18:13.006057Z","shell.execute_reply":"2026-02-21T05:18:13.026338Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"device(type='cpu')"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"def set_causal_mask(size):\n    # create a matrix with values as -ve infinity\n    mask=torch.full((size, size), float('-inf'))\n    # set the lower half of the matrix zero\n    mask=torch.triu(mask, diagonal=1)\n    return mask","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T05:18:13.029149Z","iopub.execute_input":"2026-02-21T05:18:13.029430Z","iopub.status.idle":"2026-02-21T05:18:13.046856Z","shell.execute_reply.started":"2026-02-21T05:18:13.029404Z","shell.execute_reply":"2026-02-21T05:18:13.045701Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"sequence_length=10\nmask=set_causal_mask(sequence_length)\nprint(mask)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T05:18:13.048201Z","iopub.execute_input":"2026-02-21T05:18:13.048855Z","iopub.status.idle":"2026-02-21T05:18:13.068397Z","shell.execute_reply.started":"2026-02-21T05:18:13.048811Z","shell.execute_reply":"2026-02-21T05:18:13.067453Z"}},"outputs":[{"name":"stdout","text":"tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n        [0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n        [0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n        [0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n        [0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf],\n        [0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf],\n        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., -inf],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"dummy_attention_weights=torch.randn(1,sequence_length,sequence_length)\nprint(dummy_attention_weights)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T05:18:13.069739Z","iopub.execute_input":"2026-02-21T05:18:13.070121Z","iopub.status.idle":"2026-02-21T05:18:13.090303Z","shell.execute_reply.started":"2026-02-21T05:18:13.070082Z","shell.execute_reply":"2026-02-21T05:18:13.089259Z"}},"outputs":[{"name":"stdout","text":"tensor([[[-0.9654,  0.4343, -0.9185, -0.8232, -1.1175, -2.0940, -0.3108,\n           1.4962, -0.3618, -2.0375],\n         [-2.5759,  1.6493,  1.3595,  1.4973, -1.0889,  0.2724, -0.1583,\n          -0.1888,  0.3989, -0.7162],\n         [-0.3447,  1.2901,  1.8200, -0.5086, -1.5370,  0.6569, -0.0963,\n          -0.4093,  2.0329,  0.0758],\n         [-1.6710, -0.0544,  1.4740, -0.0517, -1.3301, -0.3474, -0.2829,\n          -1.8867,  2.5350,  0.3790],\n         [ 1.6299, -0.0596,  0.0190, -2.5560, -0.0063,  0.3257,  0.1969,\n          -0.5971, -0.0352, -1.5251],\n         [ 1.0983,  0.3083, -1.8326,  1.0167,  0.3939,  1.5390, -1.2255,\n           2.7642,  0.8218,  0.3076],\n         [-0.8098, -0.5819, -0.4566,  0.4317,  1.4262,  0.7808, -0.0803,\n          -0.7487, -0.5130,  0.0109],\n         [ 0.3862,  1.6571,  1.0131, -2.3466,  0.0741,  0.7171,  1.1973,\n          -0.1694, -0.6201,  0.4520],\n         [-0.4994, -0.0443,  1.2898,  0.1607, -1.3919,  0.0539,  0.3607,\n          -0.7042,  0.0172,  1.6976],\n         [-0.8468,  1.4759,  0.4127,  0.6892,  0.1949, -2.4075, -0.7633,\n          -0.5869,  0.8882, -0.9902]]])\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"dummy_attention_weights+mask","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T05:18:13.092400Z","iopub.execute_input":"2026-02-21T05:18:13.092741Z","iopub.status.idle":"2026-02-21T05:18:13.108273Z","shell.execute_reply.started":"2026-02-21T05:18:13.092710Z","shell.execute_reply":"2026-02-21T05:18:13.107252Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"tensor([[[-0.9654,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n             -inf,    -inf,    -inf],\n         [-2.5759,  1.6493,    -inf,    -inf,    -inf,    -inf,    -inf,\n             -inf,    -inf,    -inf],\n         [-0.3447,  1.2901,  1.8200,    -inf,    -inf,    -inf,    -inf,\n             -inf,    -inf,    -inf],\n         [-1.6710, -0.0544,  1.4740, -0.0517,    -inf,    -inf,    -inf,\n             -inf,    -inf,    -inf],\n         [ 1.6299, -0.0596,  0.0190, -2.5560, -0.0063,    -inf,    -inf,\n             -inf,    -inf,    -inf],\n         [ 1.0983,  0.3083, -1.8326,  1.0167,  0.3939,  1.5390,    -inf,\n             -inf,    -inf,    -inf],\n         [-0.8098, -0.5819, -0.4566,  0.4317,  1.4262,  0.7808, -0.0803,\n             -inf,    -inf,    -inf],\n         [ 0.3862,  1.6571,  1.0131, -2.3466,  0.0741,  0.7171,  1.1973,\n          -0.1694,    -inf,    -inf],\n         [-0.4994, -0.0443,  1.2898,  0.1607, -1.3919,  0.0539,  0.3607,\n          -0.7042,  0.0172,    -inf],\n         [-0.8468,  1.4759,  0.4127,  0.6892,  0.1949, -2.4075, -0.7633,\n          -0.5869,  0.8882, -0.9902]]])"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"F.softmax(dummy_attention_weights+mask, dim=-1)# we apply softmax to the dimension that refers to the Keys","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T05:18:13.109534Z","iopub.execute_input":"2026-02-21T05:18:13.109987Z","iopub.status.idle":"2026-02-21T05:18:13.126349Z","shell.execute_reply.started":"2026-02-21T05:18:13.109955Z","shell.execute_reply":"2026-02-21T05:18:13.125446Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000],\n         [0.0144, 0.9856, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000],\n         [0.0674, 0.3456, 0.5870, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000],\n         [0.0292, 0.1468, 0.6769, 0.1472, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000],\n         [0.6273, 0.1158, 0.1253, 0.0095, 0.1221, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000],\n         [0.2234, 0.1014, 0.0119, 0.2059, 0.1104, 0.3471, 0.0000, 0.0000,\n          0.0000, 0.0000],\n         [0.0426, 0.0535, 0.0606, 0.1474, 0.3985, 0.2090, 0.0883, 0.0000,\n          0.0000, 0.0000],\n         [0.0873, 0.3113, 0.1635, 0.0057, 0.0639, 0.1216, 0.1966, 0.0501,\n          0.0000, 0.0000],\n         [0.0571, 0.0901, 0.3420, 0.1106, 0.0234, 0.0994, 0.1351, 0.0466,\n          0.0958, 0.0000],\n         [0.0319, 0.3256, 0.1124, 0.1483, 0.0904, 0.0067, 0.0347, 0.0414,\n          0.1809, 0.0276]]])"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"class PositionalEncoding(nn.Module):\n    def __init__(self, max_seq_len, embedding_dimension):\n        super().__init__()\n        self.max_seq_len=max_seq_len\n        self.embedding_dimension=embedding_dimension\n        pem=torch.zeros(max_seq_len,embedding_dimension)\n        positions=torch.arange(0,max_seq_len).unsqueeze(1).float()\n        even_positions=torch.arange(0,embedding_dimension,2 ).float()\n        exponential_term=torch.log(torch.tensor(10000.0))/embedding_dimension\n        div_term=torch.exp(even_positions * -(exponential_term))\n        # Sine to even indices\n        pem[:,0::2]=torch.sin(positions * div_term)\n        pem[:,1::2]=torch.cos(positions * div_term)\n        self.register_buffer('pem', pem.unsqueeze(0))\n    def forward(self, x):\n        # shape of x is [batch_size, length_of_seq, embedding_dimension]\n        length_of_seq=x.size(1)\n        return self.pem[:,:length_of_seq, :]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T05:18:13.127428Z","iopub.execute_input":"2026-02-21T05:18:13.127799Z","iopub.status.idle":"2026-02-21T05:18:13.145150Z","shell.execute_reply.started":"2026-02-21T05:18:13.127766Z","shell.execute_reply":"2026-02-21T05:18:13.144038Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def set_padding_mask(sequence,padding_index):\n    return sequence==padding_index\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T05:18:13.146605Z","iopub.execute_input":"2026-02-21T05:18:13.147034Z","iopub.status.idle":"2026-02-21T05:18:13.167835Z","shell.execute_reply.started":"2026-02-21T05:18:13.146992Z","shell.execute_reply":"2026-02-21T05:18:13.166593Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"class DecoderBlock(nn.Module):\n    def __init__(self, embedding_dimension, sequence_length, n_attention_heads, ff_hidden_layers=1024, dropout=.01):\n        super().__init__()\n        self.ln_1=nn.LayerNorm(embedding_dimension)\n        self.multihead_attention=nn.MultiheadAttention(embedding_dimension,n_attention_heads, dropout, batch_first=True)\n        self.dropout_1=nn.Dropout(dropout)\n        self.ln_2=nn.LayerNorm(embedding_dimension)\n        self.ffn=nn.Sequential(\n            nn.Linear(embedding_dimension,ff_hidden_layers ),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(ff_hidden_layers,embedding_dimension)\n           \n        )\n        self.dropout_2=nn.Dropout(dropout)\n    def forward(self,x, causal_mask=None):\n        x_norm=self.ln_1(x)\n        att,_=self.multihead_attention(x_norm, x_norm, x_norm, attn_mask=causal_mask)\n        att=self.dropout_1(att)\n        x=x+att\n        x_ffn_norm=self.ln_2(x)\n        x_ffn=self.ffn(x_ffn_norm)\n        x=x+self.dropout_2(x_ffn)\n        return x\n        \n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T05:40:35.360551Z","iopub.execute_input":"2026-02-21T05:40:35.360906Z","iopub.status.idle":"2026-02-21T05:40:35.369509Z","shell.execute_reply.started":"2026-02-21T05:40:35.360878Z","shell.execute_reply":"2026-02-21T05:40:35.368101Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"dummy_sequence=torch.randn(1, 10, 12)\nprint(dummy_sequence)\ncausal_mask=set_causal_mask(10)\nprint(causal_mask)\ndecoder=DecoderBlock(12,10,4)\n\noutput=decoder(dummy_sequence,causal_mask=causal_mask)\nprint(output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T05:40:36.139155Z","iopub.execute_input":"2026-02-21T05:40:36.139485Z","iopub.status.idle":"2026-02-21T05:40:36.164734Z","shell.execute_reply.started":"2026-02-21T05:40:36.139457Z","shell.execute_reply":"2026-02-21T05:40:36.163864Z"}},"outputs":[{"name":"stdout","text":"tensor([[[ 3.0058e-01, -1.1193e-01, -1.7671e+00, -2.1940e-01,  2.6723e+00,\n          -5.2958e-01,  2.7066e-02,  5.8608e-01, -1.6722e+00,  1.8119e+00,\n          -2.3175e+00,  8.0755e-01],\n         [ 4.8411e-01, -6.9740e-01, -1.8349e+00,  5.9242e-01, -3.9815e-01,\n           7.7734e-01,  5.3490e-01, -6.4500e-01, -6.5829e-01, -3.4404e-01,\n           4.3873e-01,  6.6312e-02],\n         [-2.5691e+00,  1.4824e-02,  2.5424e+00,  7.5870e-01, -1.2597e+00,\n          -8.9006e-01, -7.8506e-01,  9.5710e-01,  2.9448e-02, -3.3721e-01,\n           7.3392e-01, -7.1969e-01],\n         [ 8.0331e-01,  7.6176e-01,  4.9357e-01,  2.0885e+00,  4.1913e-01,\n           3.0149e-01,  3.2093e-01, -2.6646e+00,  9.7319e-01,  7.3366e-01,\n           1.6656e+00, -2.4378e-01],\n         [ 1.1523e+00, -1.0555e+00,  1.1867e-01, -3.9691e-01,  1.0793e+00,\n          -3.7202e-01,  1.4140e+00, -2.7426e-01, -4.8509e-02,  1.7031e-01,\n           5.7462e-01,  2.4806e-01],\n         [ 1.0352e+00,  1.4812e-01, -1.5510e-01,  4.7041e-01,  1.1621e+00,\n           1.1478e+00,  1.0045e+00,  9.6171e-02,  1.4882e+00,  7.8179e-02,\n          -1.2123e+00, -1.4357e+00],\n         [ 3.5474e-01, -1.8037e+00,  1.4211e+00,  1.6193e-01,  5.5658e-01,\n          -1.0750e+00,  2.6714e-01,  1.1484e+00,  1.9005e-03, -3.4116e-01,\n          -7.8013e-01,  8.6575e-01],\n         [ 2.2413e+00, -6.7898e-01, -1.3398e+00,  5.7411e-01, -1.5947e-01,\n           8.2029e-01, -2.6263e-01, -4.9440e-02,  1.5839e+00, -1.9140e+00,\n          -2.0996e-02,  1.1183e+00],\n         [-1.4080e+00, -2.7512e-01, -5.9622e-01,  1.0819e+00,  1.6196e+00,\n           2.6108e-01,  1.0407e+00,  9.9530e-01, -7.9880e-01, -3.1384e-01,\n           2.7890e+00, -2.9674e+00],\n         [ 2.4578e-01,  1.5346e+00,  1.2732e+00,  5.9407e-02, -2.9218e+00,\n           1.5461e-01,  1.1594e+00, -4.6654e-01, -7.0169e-01,  4.2287e-01,\n           2.1739e-01,  1.8142e+00]]])\ntensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n        [0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n        [0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n        [0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n        [0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf],\n        [0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf],\n        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., -inf],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\ntensor([[[ 0.2777, -0.7429, -2.2917, -0.6425,  2.8165, -0.2506,  0.2954,\n           0.4363, -1.9436,  1.5700, -1.8178,  1.4792],\n         [ 0.2423, -0.4285, -1.8921,  0.5386, -0.3414,  1.0752,  0.5644,\n          -0.8380, -1.2819, -0.3519,  0.8817,  0.5210],\n         [-2.8988,  0.3597,  2.3720,  1.1376, -0.8325, -0.4661, -0.3940,\n           0.5706,  0.0493,  0.2486,  1.1435, -0.3691],\n         [ 0.8834,  0.7382,  0.6906,  2.3924,  0.1067,  0.3233,  0.1933,\n          -2.6971,  0.7278,  1.2281,  2.3985, -0.2586],\n         [ 1.3582, -1.0277,  0.2442, -0.4844,  1.0735, -0.3962,  1.6350,\n          -0.5497, -0.0161,  0.6932,  0.5879,  0.4048],\n         [ 0.3692,  0.2835, -0.0479,  0.5171,  0.8417,  1.1073,  0.8380,\n           0.1186,  1.4365,  0.1312, -0.4872, -1.8194],\n         [ 0.1140, -1.9324,  1.5927,  0.0748,  0.7563, -1.0109,  0.4663,\n           1.2314,  0.2560,  0.0983, -0.7878,  1.0302],\n         [ 2.2349, -0.7884, -1.0119,  0.3977,  0.0591,  0.8247, -0.4897,\n          -0.3120,  1.3699, -2.0948,  0.0913,  0.7198],\n         [-1.3768, -0.2350, -0.6554,  1.0522,  1.5594,  0.5406,  1.0956,\n           0.8572, -0.8038, -0.4838,  2.7877, -2.5384],\n         [ 0.1325,  1.8147,  1.4551,  0.3900, -2.7408, -0.1654,  1.1295,\n          -0.7380, -0.5921,  0.3645,  0.3910,  1.7415]]],\n       grad_fn=<AddBackward0>)\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}