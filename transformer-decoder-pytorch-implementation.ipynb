{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31286,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Components\nToken Embedding\n\nPositional Encoding\n\nCausal Masking\n\nMulti-Head Self Attention\n\nFeed Forward Network\n\nLayer Normalization\n\nDropout\n\nTraining & Evaluation Pipeline","metadata":{}},{"cell_type":"code","source":"text_url='https://www.gutenberg.org/files/2701/2701-0.txt'\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T13:51:56.421851Z","iopub.execute_input":"2026-02-25T13:51:56.422127Z","iopub.status.idle":"2026-02-25T13:51:56.429847Z","shell.execute_reply.started":"2026-02-25T13:51:56.422096Z","shell.execute_reply":"2026-02-25T13:51:56.429244Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import os, urllib\ntarget_dir=os.path.join(os.getcwd(),'text')\nprint(target_dir)\nfile_path=os.path.join(target_dir, 'text.txt')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T13:51:56.431488Z","iopub.execute_input":"2026-02-25T13:51:56.431797Z","iopub.status.idle":"2026-02-25T13:51:56.444040Z","shell.execute_reply.started":"2026-02-25T13:51:56.431774Z","shell.execute_reply":"2026-02-25T13:51:56.443436Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/text\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"if not os.path.exists(target_dir):\n    os.makedirs(target_dir)\ntry:\n    urllib.request.urlretrieve(text_url,file_path)\n    print(f\"File downloaded tp {target_dir}\")\nexcept Exception as e:\n    print(e)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T13:51:56.444772Z","iopub.execute_input":"2026-02-25T13:51:56.445333Z","iopub.status.idle":"2026-02-25T13:51:58.190474Z","shell.execute_reply.started":"2026-02-25T13:51:56.445310Z","shell.execute_reply":"2026-02-25T13:51:58.189804Z"}},"outputs":[{"name":"stdout","text":"File downloaded tp /kaggle/working/text\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"with open (file_path, 'r',encoding=\"utf-8\") as f:\n    lines=f.readlines()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T13:51:58.191364Z","iopub.execute_input":"2026-02-25T13:51:58.191621Z","iopub.status.idle":"2026-02-25T13:51:58.205595Z","shell.execute_reply.started":"2026-02-25T13:51:58.191599Z","shell.execute_reply":"2026-02-25T13:51:58.204692Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"new_file_path=os.path.join(target_dir, 'text_cleaned.txt')\nwith open (new_file_path, 'w+') as wr:\n    for i, line in enumerate(lines):     \n        \n        if i>=817:\n            wr.write(line)\n                     \n          \n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T13:51:58.206724Z","iopub.execute_input":"2026-02-25T13:51:58.207008Z","iopub.status.idle":"2026-02-25T13:51:58.229879Z","shell.execute_reply.started":"2026-02-25T13:51:58.206978Z","shell.execute_reply":"2026-02-25T13:51:58.229124Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# read the contents of the input file\ndef read_input_text(file_path):    \n    with open (file_path, 'r',encoding=\"utf-8\") as f:\n        text=f.read()\n\n    return text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T13:51:58.230810Z","iopub.execute_input":"2026-02-25T13:51:58.231103Z","iopub.status.idle":"2026-02-25T13:51:58.235478Z","shell.execute_reply.started":"2026-02-25T13:51:58.231049Z","shell.execute_reply":"2026-02-25T13:51:58.234748Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"text=read_input_text(new_file_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T13:51:58.237683Z","iopub.execute_input":"2026-02-25T13:51:58.237961Z","iopub.status.idle":"2026-02-25T13:51:58.250617Z","shell.execute_reply.started":"2026-02-25T13:51:58.237940Z","shell.execute_reply":"2026-02-25T13:51:58.249919Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"text[:500]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T13:51:58.251632Z","iopub.execute_input":"2026-02-25T13:51:58.251893Z","iopub.status.idle":"2026-02-25T13:51:58.258399Z","shell.execute_reply.started":"2026-02-25T13:51:58.251854Z","shell.execute_reply":"2026-02-25T13:51:58.257791Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"'CHAPTER 1. Loomings.\\n\\nCall me Ishmael. Some years ago—never mind how long precisely—having\\nlittle or no money in my purse, and nothing particular to interest me\\non shore, I thought I would sail about a little and see the watery part\\nof the world. It is a way I have of driving off the spleen and\\nregulating the circulation. Whenever I find myself growing grim about\\nthe mouth; whenever it is a damp, drizzly November in my soul; whenever\\nI find myself involuntarily pausing before coffin warehouses, '"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"from collections import Counter\nimport re\nclass Novel_Tokenizer:\n    def __init__(self, vocabulary_size=10000):\n        self.vocabulary_size=vocabulary_size\n        self.w2i={'<pad>':0, '<unk>':1,'<nl>':2}\n        self.i2w={0:'<pad>',1:'<unk>',2: '<nl>'}\n        self.counter=Counter()\n        self.vocab=[]\n        \n    def build_vocabulary(self, texts, min_freq=2):\n        tokens=self.tokenize(texts)\n        self.counter.update(tokens)\n        most_common_tokens=self.counter.most_common(self.vocabulary_size-len(self.w2i))\n        idx=3\n        for word, freq in most_common_tokens:\n            if freq > min_freq:\n                self.w2i[word]=idx\n                self.i2w[idx]=word\n                idx+=1\n        \n    def tokenize(self, text):\n        #text_lower=text.lower()\n        text = text.replace('\\n\\n', '\\n').replace('\\n','<nl>').strip()    \n        return re.findall(r\"\\w+(?:'\\w+)?|<nl>|[^\\w\\s]\", text)\n                \n    \n        \n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T13:51:58.259380Z","iopub.execute_input":"2026-02-25T13:51:58.259588Z","iopub.status.idle":"2026-02-25T13:51:58.270395Z","shell.execute_reply.started":"2026-02-25T13:51:58.259568Z","shell.execute_reply":"2026-02-25T13:51:58.269708Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"tokenizer=Novel_Tokenizer()\ntokenizer.build_vocabulary(text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T13:51:58.271154Z","iopub.execute_input":"2026-02-25T13:51:58.271426Z","iopub.status.idle":"2026-02-25T13:51:58.453768Z","shell.execute_reply.started":"2026-02-25T13:51:58.271404Z","shell.execute_reply":"2026-02-25T13:51:58.453143Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def create_training_sequences(text, tokenizer, sequence_length=30):\n    inputs=[]\n    targets=[]\n    \n    tokens=tokenizer.tokenize(text)#list(tokenizer.w2i.keys())\n    print(len(tokens))\n    for i in range(len(tokens)-sequence_length):\n        inp=tokens[i: i+sequence_length]\n        tar=tokens[i+1:i+sequence_length+1]\n        # print(inp)\n        # print()\n        # print(tar)\n        \n        num_inp=[tokenizer.w2i.get(token,tokenizer.w2i['<unk>']) for token in inp]\n        num_tar=[tokenizer.w2i.get(token,tokenizer.w2i['<unk>']) for token in tar]\n        # print(num_inp)\n        # print()\n        # print(num_tar)\n        # if i==5:\n        #     break\n        \n        inputs.append(num_inp)\n        targets.append(num_tar)\n    return inputs, targets\n    \n        \n    \n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T13:51:58.454724Z","iopub.execute_input":"2026-02-25T13:51:58.455013Z","iopub.status.idle":"2026-02-25T13:51:58.461260Z","shell.execute_reply.started":"2026-02-25T13:51:58.454983Z","shell.execute_reply":"2026-02-25T13:51:58.460541Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"inputs, targets=create_training_sequences(text,tokenizer, 30)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T13:51:58.462189Z","iopub.execute_input":"2026-02-25T13:51:58.462526Z","iopub.status.idle":"2026-02-25T13:52:01.154597Z","shell.execute_reply.started":"2026-02-25T13:51:58.462504Z","shell.execute_reply":"2026-02-25T13:52:01.153816Z"}},"outputs":[{"name":"stdout","text":"277245\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"len(tokenizer.w2i)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T13:52:01.155550Z","iopub.execute_input":"2026-02-25T13:52:01.155845Z","iopub.status.idle":"2026-02-25T13:52:01.161214Z","shell.execute_reply.started":"2026-02-25T13:52:01.155822Z","shell.execute_reply":"2026-02-25T13:52:01.160530Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"6976"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"import torch as torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, random_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T13:52:01.162483Z","iopub.execute_input":"2026-02-25T13:52:01.162774Z","iopub.status.idle":"2026-02-25T13:52:04.914632Z","shell.execute_reply.started":"2026-02-25T13:52:01.162743Z","shell.execute_reply":"2026-02-25T13:52:04.913840Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"class Novel_Dataset(nn.Module):\n    def __init__(self, inputs, targets):\n        self.inputs=torch.tensor(inputs, dtype=torch.long)\n        self.targets=torch.tensor(targets, dtype=torch.long)\n        \n    def __len__(self):\n        return len(self.inputs)\n    def __getitem__(self, idx):\n        return self.inputs[idx], self.targets[idx]\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T13:52:04.915625Z","iopub.execute_input":"2026-02-25T13:52:04.915994Z","iopub.status.idle":"2026-02-25T13:52:04.920509Z","shell.execute_reply.started":"2026-02-25T13:52:04.915961Z","shell.execute_reply":"2026-02-25T13:52:04.919966Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# split into train and val datasets\ntr_size=.8\nds=Novel_Dataset(inputs, targets)\ntr_size=int(tr_size * len(ds))\nval_size=len(ds)-tr_size\ntr_ds, val_ds=random_split(ds, [tr_size, val_size])\nprint(f\"Train Dataset size: {len(tr_ds)}\")\nprint(f\"Val Dataset size: {len(val_ds)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T13:52:04.921310Z","iopub.execute_input":"2026-02-25T13:52:04.921577Z","iopub.status.idle":"2026-02-25T13:52:06.291488Z","shell.execute_reply.started":"2026-02-25T13:52:04.921548Z","shell.execute_reply":"2026-02-25T13:52:06.290828Z"}},"outputs":[{"name":"stdout","text":"Train Dataset size: 221772\nVal Dataset size: 55443\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"batch_size=32\ntr_dl=DataLoader(tr_ds,batch_size=batch_size,shuffle=True )\nval_dl=DataLoader(tr_ds,batch_size=batch_size,shuffle=False )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T13:52:06.292389Z","iopub.execute_input":"2026-02-25T13:52:06.292619Z","iopub.status.idle":"2026-02-25T13:52:06.296629Z","shell.execute_reply.started":"2026-02-25T13:52:06.292598Z","shell.execute_reply":"2026-02-25T13:52:06.295960Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"batch=next(iter(tr_dl))\ninp, tar=batch\nprint(\"Inputs=>\",\" \".join(tokenizer.i2w.get(item.item(),tokenizer.w2i['<unk>']) for item in inp[1][:10]))\nprint(\"Targets=>\",\" \".join(tokenizer.i2w.get(item.item(), tokenizer.w2i['<unk>']) for item in tar[1][:10]))\nprint(inp.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T13:52:06.297417Z","iopub.execute_input":"2026-02-25T13:52:06.297760Z","iopub.status.idle":"2026-02-25T13:52:06.352116Z","shell.execute_reply.started":"2026-02-25T13:52:06.297732Z","shell.execute_reply":"2026-02-25T13:52:06.351400Z"}},"outputs":[{"name":"stdout","text":"Inputs=> to me , Starbuck , <nl> about those <unk> owners\nTargets=> me , Starbuck , <nl> about those <unk> owners ,\ntorch.Size([32, 30])\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"class PositionalEncoding(nn.Module):\n    def __init__(self, max_seq_len, embedding_dimension):\n        super().__init__()\n        self.max_seq_len=max_seq_len\n        self.embedding_dimension=embedding_dimension\n        pem=torch.zeros(max_seq_len,embedding_dimension)\n        positions=torch.arange(0,max_seq_len).unsqueeze(1).float()\n        even_positions=torch.arange(0,embedding_dimension,2 ).float()\n        exponential_term=torch.log(torch.tensor(10000.0))/embedding_dimension\n        div_term=torch.exp(even_positions * -(exponential_term))\n        # Sine to even indices\n        pem[:,0::2]=torch.sin(positions * div_term)\n        pem[:,1::2]=torch.cos(positions * div_term)\n        self.register_buffer('pem', pem.unsqueeze(0))\n    def forward(self, x):\n        # shape of x is [batch_size, length_of_seq, embedding_dimension]\n        length_of_seq=x.size(1)\n        return self.pem[:,:length_of_seq, :]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T13:52:06.353082Z","iopub.execute_input":"2026-02-25T13:52:06.353364Z","iopub.status.idle":"2026-02-25T13:52:06.358981Z","shell.execute_reply.started":"2026-02-25T13:52:06.353334Z","shell.execute_reply":"2026-02-25T13:52:06.358267Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"def set_padding_mask(sequence,padding_index):\n    return sequence==padding_index\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T13:52:06.359908Z","iopub.execute_input":"2026-02-25T13:52:06.360157Z","iopub.status.idle":"2026-02-25T13:52:06.374144Z","shell.execute_reply.started":"2026-02-25T13:52:06.360135Z","shell.execute_reply":"2026-02-25T13:52:06.373565Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"def set_causal_mask(size):\n    # create a matrix with values as -ve infinity\n    mask=torch.full((size, size), float('-inf'))\n    # set the lower half of the matrix zero\n    mask=torch.triu(mask, diagonal=1)\n    return mask","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T13:52:06.374912Z","iopub.execute_input":"2026-02-25T13:52:06.375209Z","iopub.status.idle":"2026-02-25T13:52:06.385695Z","shell.execute_reply.started":"2026-02-25T13:52:06.375180Z","shell.execute_reply":"2026-02-25T13:52:06.384836Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# Decoder using pytorch's Decoder layers\nclass Decoder(nn.Module):\n    def __init__(self, vocab_size, embedding_dimen, max_seq_length=20, dropout=.01, n_heads=4,ffn_hidden_layers=80, n_decoder_layers=2):\n        super().__init__()\n        self.embedding_dimension=embedding_dimen\n        self.embedding=nn.Embedding(vocab_size,embedding_dimen, padding_idx=0 )\n        self.pos_enc=PositionalEncoding(max_seq_length, embedding_dimen)\n        self.dropout=nn.Dropout(dropout)\n        decoder_layer=nn.TransformerDecoderLayer(embedding_dimen,n_heads,ffn_hidden_layers, dropout, batch_first=True, norm_first=True)\n        self.stacked_decoders=nn.TransformerDecoder(decoder_layer,n_decoder_layers)\n        self.ln=nn.LayerNorm(embedding_dimen)\n        self.out_probs=nn.Linear(embedding_dimen, vocab_size)\n    def forward(self,x):\n        padding_mask = set_padding_mask(x, padding_index=0)\n        causal_mask = set_causal_mask(x.size(1)).to(x.device)\n\n        x=self.embedding(x)\n        #print(x.shape)\n        x=x+self.pos_enc(x)\n        x=self.dropout(x)\n\n        x = self.stacked_decoders(\n            tgt=x,                              \n            memory=x,                           \n            tgt_mask=causal_mask,               \n            memory_mask=causal_mask,              \n            tgt_key_padding_mask=padding_mask,  \n            memory_key_padding_mask=padding_mask \n            \n        )\n        output=self.out_probs(x)\n        return output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T13:52:06.388628Z","iopub.execute_input":"2026-02-25T13:52:06.388904Z","iopub.status.idle":"2026-02-25T13:52:06.398909Z","shell.execute_reply.started":"2026-02-25T13:52:06.388881Z","shell.execute_reply":"2026-02-25T13:52:06.398262Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"inp=torch.randint(1, 200, (2, 30))\nprint(inp.shape)\ndec=Decoder(200,28,30,.01,4,50,2)\nprint(dec)\ndec.eval()\nwith torch.no_grad():\n    output = dec(inp)\n\nprint(output.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T13:52:06.399784Z","iopub.execute_input":"2026-02-25T13:52:06.400043Z","iopub.status.idle":"2026-02-25T13:52:06.918079Z","shell.execute_reply.started":"2026-02-25T13:52:06.400009Z","shell.execute_reply":"2026-02-25T13:52:06.917310Z"}},"outputs":[{"name":"stdout","text":"torch.Size([2, 30])\nDecoder(\n  (embedding): Embedding(200, 28, padding_idx=0)\n  (pos_enc): PositionalEncoding()\n  (dropout): Dropout(p=0.01, inplace=False)\n  (stacked_decoders): TransformerDecoder(\n    (layers): ModuleList(\n      (0-1): 2 x TransformerDecoderLayer(\n        (self_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=28, out_features=28, bias=True)\n        )\n        (multihead_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=28, out_features=28, bias=True)\n        )\n        (linear1): Linear(in_features=28, out_features=50, bias=True)\n        (dropout): Dropout(p=0.01, inplace=False)\n        (linear2): Linear(in_features=50, out_features=28, bias=True)\n        (norm1): LayerNorm((28,), eps=1e-05, elementwise_affine=True)\n        (norm2): LayerNorm((28,), eps=1e-05, elementwise_affine=True)\n        (norm3): LayerNorm((28,), eps=1e-05, elementwise_affine=True)\n        (dropout1): Dropout(p=0.01, inplace=False)\n        (dropout2): Dropout(p=0.01, inplace=False)\n        (dropout3): Dropout(p=0.01, inplace=False)\n      )\n    )\n  )\n  (ln): LayerNorm((28,), eps=1e-05, elementwise_affine=True)\n  (out_probs): Linear(in_features=28, out_features=200, bias=True)\n)\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6044: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([2, 30, 200])\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6044: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"class NovelGenerator(nn.Module):\n    def __init__(self,vocabulary_size, embedding_dimension=128, n_heads=4,\n                dec_layers=2, ffn_hidden=1024, max_len=300, dropout=.1, pad_index=0):\n        super().__init__()\n        self.decoder=Decoder(\n            vocabulary_size,embedding_dimension, max_len, dropout, n_heads, ffn_hidden,dec_layers \n        )\n        self.pad_idx=pad_index\n        self.vocab_size=vocabulary_size\n    def forward(self,x):\n        return self.decoder(x)\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T13:52:06.919005Z","iopub.execute_input":"2026-02-25T13:52:06.919449Z","iopub.status.idle":"2026-02-25T13:52:06.924590Z","shell.execute_reply.started":"2026-02-25T13:52:06.919424Z","shell.execute_reply":"2026-02-25T13:52:06.923888Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# test \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T13:52:06.925587Z","iopub.execute_input":"2026-02-25T13:52:06.925977Z","iopub.status.idle":"2026-02-25T13:52:06.940739Z","shell.execute_reply.started":"2026-02-25T13:52:06.925946Z","shell.execute_reply":"2026-02-25T13:52:06.940124Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"tokenizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T13:52:06.941517Z","iopub.execute_input":"2026-02-25T13:52:06.942031Z","iopub.status.idle":"2026-02-25T13:52:06.954126Z","shell.execute_reply.started":"2026-02-25T13:52:06.942008Z","shell.execute_reply":"2026-02-25T13:52:06.953540Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"<__main__.Novel_Tokenizer at 0x794471d2d610>"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"vocab_size=max(tokenizer.w2i.values())+1\npad_idx=tokenizer.w2i['<pad>']\nmodel=NovelGenerator(vocab_size, 512,4,2,1024,300,.1,pad_idx)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T13:52:06.955023Z","iopub.execute_input":"2026-02-25T13:52:06.955364Z","iopub.status.idle":"2026-02-25T13:52:07.296919Z","shell.execute_reply.started":"2026-02-25T13:52:06.955340Z","shell.execute_reply":"2026-02-25T13:52:07.296111Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"NovelGenerator(\n  (decoder): Decoder(\n    (embedding): Embedding(6977, 512, padding_idx=0)\n    (pos_enc): PositionalEncoding()\n    (dropout): Dropout(p=0.1, inplace=False)\n    (stacked_decoders): TransformerDecoder(\n      (layers): ModuleList(\n        (0-1): 2 x TransformerDecoderLayer(\n          (self_attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n          )\n          (multihead_attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n          )\n          (linear1): Linear(in_features=512, out_features=1024, bias=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n          (linear2): Linear(in_features=1024, out_features=512, bias=True)\n          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (dropout1): Dropout(p=0.1, inplace=False)\n          (dropout2): Dropout(p=0.1, inplace=False)\n          (dropout3): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    (out_probs): Linear(in_features=512, out_features=6977, bias=True)\n  )\n)"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"# # inspect model & a single batch\n# emb = model.decoder.embedding\n# print(\"embedding.num_embeddings:\", emb.num_embeddings)\n# print(\"embedding.padding_idx:\", emb.padding_idx if hasattr(emb,'padding_idx') else None)\n# print(\"model.vocab_size (if set):\", getattr(model, \"vocab_size\", None))\n# print(\"batch min/max:\", inputs.min().item(), inputs.max().item())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T13:52:07.297956Z","iopub.execute_input":"2026-02-25T13:52:07.298424Z","iopub.status.idle":"2026-02-25T13:52:07.301707Z","shell.execute_reply.started":"2026-02-25T13:52:07.298390Z","shell.execute_reply":"2026-02-25T13:52:07.301123Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"loss_fn=nn.CrossEntropyLoss(ignore_index=tokenizer.w2i['<pad>'])\noptimizer=torch.optim.Adam(model.parameters(), lr=.001)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T13:52:07.302445Z","iopub.execute_input":"2026-02-25T13:52:07.302666Z","iopub.status.idle":"2026-02-25T13:52:09.775708Z","shell.execute_reply.started":"2026-02-25T13:52:07.302645Z","shell.execute_reply":"2026-02-25T13:52:09.774949Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"def train_model(model,train_dl, test_dl,loss_fn,optimizer,epochs=10,device=None):\n    if device is None:\n        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model=model.to(device)\n    history={\"train_acc\":[], \"test_acc\":[],\"train_loss\":[],\"test_loss\":[]}\n    \n    for epoch in range(epochs):\n        print(f\"epoch: {epoch+1}\")\n        model.train()\n        tr_loss=0\n        total_train_size=0\n        tr_correct=0\n        for inputs, labels in train_dl:\n            optimizer.zero_grad()\n            if not torch.is_tensor(inputs):\n                inputs = torch.tensor(inputs, dtype=torch.long)\n            if not torch.is_tensor(labels):\n                labels = torch.tensor(labels, dtype=torch.long)\n\n            inputs=inputs.to(device)\n            labels=labels.to(device)\n            #print(inputs.max())\n            outputs=model(inputs)\n            #print(outputs.shape)\n           \n            if outputs.dim() == 3:\n                B, T, V = outputs.shape                \n                if labels.dim() == 2 and labels.shape[1] == T:\n                    logits = outputs.reshape(-1, V)          \n                    targets = labels.reshape(-1).long()    \n                \n                elif labels.dim() == 2 and labels.shape[1] == V:\n                    outputs = outputs.permute(0, 2, 1)       \n                    logits = outputs.reshape(-1, outputs.size(-1))\n                    targets = labels.reshape(-1).long()\n                else:\n                    raise RuntimeError(f'unexpected shapes: outputs={outputs.shape}, labels={labels.shape}')\n            elif outputs.dim() == 2:                \n                logits = outputs\n                targets = labels.reshape(-1).long()\n            else:\n                raise RuntimeError(f'unexpected outputs.dim()={outputs.dim()}')\n\n            loss = loss_fn(logits, targets)\n            #loss=loss_fn(outputs, labels)\n            # print(\"loss.requires_grad:\", loss.requires_grad)\n            # print(\"loss.grad_fn:\", getattr(loss, \"grad_fn\", None))\n            # print(\"any param requires_grad?:\", any(p.requires_grad for p in model.parameters()))\n            # print(\"model training mode:\", model.training)\n            \n            loss.backward()\n            optimizer.step()\n    \n            predicted=logits.argmax(dim=1)\n            total_train_size+=targets.size(0)\n            tr_correct+=(predicted==targets).sum().item()\n            tr_loss+=loss.item()* targets.size(0)\n    \n            train_acc=100* tr_correct/total_train_size\n            tr_avg_loss=tr_loss/total_train_size\n        print(f\"train acc: {train_acc} train loss: {tr_avg_loss}\")\n            \n        model.eval()\n        test_loss=0\n        total_test_size=0\n        test_correct=0\n        with torch.no_grad():\n            for inputs, labels in test_dl:\n                if not torch.is_tensor(inputs):\n                    inputs = torch.tensor(inputs, dtype=torch.long)\n                if not torch.is_tensor(labels):\n                    labels = torch.tensor(labels, dtype=torch.long)\n                inputs=inputs.to(device)\n                labels=labels.to(device)\n    \n                outputs=model(inputs)\n                if outputs.dim() == 3:\n                    B, T, V = outputs.shape                \n                    if labels.dim() == 2 and labels.shape[1] == T:\n                        logits = outputs.reshape(-1, V)          \n                        targets = labels.reshape(-1).long()    \n                \n                    elif labels.dim() == 2 and labels.shape[1] == V:\n                        outputs = outputs.permute(0, 2, 1)       \n                        logits = outputs.reshape(-1, outputs.size(-1))\n                        targets = labels.reshape(-1).long()\n                    else:\n                        raise RuntimeError(f'unexpected shapes: outputs={outputs.shape}, labels={labels.shape}')\n                elif outputs.dim() == 2:                \n                    logits = outputs\n                    targets = labels.reshape(-1).long()\n                else:\n                    raise RuntimeError(f'unexpected outputs.dim()={outputs.dim()}')\n                loss=loss_fn(logits, targets)          \n\n                #loss=loss_fn(outputs, labels)\n                predicted=logits.argmax(dim=1)\n                total_test_size+=targets.size(0)\n                test_correct+=(predicted==targets).sum().item()\n                test_loss+=loss.item()* targets.size(0)\n        \n                test_acc=100* test_correct/total_test_size\n                test_avg_loss=test_loss/total_test_size\n            print(f\"test acc: {test_acc} test loss: {test_avg_loss}\")\n            \n        history['train_acc'].append(train_acc)\n        history['test_acc'].append(test_acc)\n        history['train_loss'].append(tr_avg_loss)\n        history['test_loss'].append(test_avg_loss)\n    return history\n        \n\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T13:52:09.776761Z","iopub.execute_input":"2026-02-25T13:52:09.777231Z","iopub.status.idle":"2026-02-25T13:52:09.792919Z","shell.execute_reply.started":"2026-02-25T13:52:09.777196Z","shell.execute_reply":"2026-02-25T13:52:09.792258Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"train_model(model,tr_dl, val_dl,loss_fn,optimizer,epochs=10,device=None)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T13:52:09.793882Z","iopub.execute_input":"2026-02-25T13:52:09.794211Z","iopub.status.idle":"2026-02-25T14:18:48.916563Z","shell.execute_reply.started":"2026-02-25T13:52:09.794177Z","shell.execute_reply":"2026-02-25T14:18:48.915922Z"}},"outputs":[{"name":"stdout","text":"epoch: 1\ntrain acc: 33.95678143919581 train loss: 3.159954682673314\ntest acc: 61.757330351291714 test loss: 1.5596431598448661\nepoch: 2\ntrain acc: 53.98990855473188 train loss: 1.9351130065090945\ntest acc: 77.77601921492945 test loss: 0.961295738832656\nepoch: 3\ntrain acc: 63.34722147069964 train loss: 1.552745838597716\ntest acc: 84.06821720806353 test loss: 0.7481020543941796\nepoch: 4\ntrain acc: 68.77383078116263 train loss: 1.3484201376704283\ntest acc: 86.897925196448 test loss: 0.6464778803223223\nepoch: 5\ntrain acc: 72.20208141695075 train loss: 1.2234972960900394\ntest acc: 88.56588448196045 test loss: 0.5926040038357604\nepoch: 6\ntrain acc: 74.5641169008411 train loss: 1.1371958927014834\ntest acc: 89.5054079565199 test loss: 0.5538992807068867\nepoch: 7\ntrain acc: 76.27779882041015 train loss: 1.0749806798648505\ntest acc: 89.9734111309513 test loss: 0.5350808461154541\nepoch: 8\ntrain acc: 77.60797876497784 train loss: 1.0258590707051243\ntest acc: 90.23214532643135 test loss: 0.5230813679667952\nepoch: 9\ntrain acc: 78.61988889490107 train loss: 0.9875304320113857\ntest acc: 90.81926483054669 test loss: 0.49944642878988355\nepoch: 10\ntrain acc: 79.41576634261013 train loss: 0.9560395882758924\ntest acc: 90.93532997853652 test loss: 0.4916005716002753\n","output_type":"stream"},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"{'train_acc': [33.95678143919581,\n  53.98990855473188,\n  63.34722147069964,\n  68.77383078116263,\n  72.20208141695075,\n  74.5641169008411,\n  76.27779882041015,\n  77.60797876497784,\n  78.61988889490107,\n  79.41576634261013],\n 'test_acc': [61.757330351291714,\n  77.77601921492945,\n  84.06821720806353,\n  86.897925196448,\n  88.56588448196045,\n  89.5054079565199,\n  89.9734111309513,\n  90.23214532643135,\n  90.81926483054669,\n  90.93532997853652],\n 'train_loss': [3.159954682673314,\n  1.9351130065090945,\n  1.552745838597716,\n  1.3484201376704283,\n  1.2234972960900394,\n  1.1371958927014834,\n  1.0749806798648505,\n  1.0258590707051243,\n  0.9875304320113857,\n  0.9560395882758924],\n 'test_loss': [1.5596431598448661,\n  0.961295738832656,\n  0.7481020543941796,\n  0.6464778803223223,\n  0.5926040038357604,\n  0.5538992807068867,\n  0.5350808461154541,\n  0.5230813679667952,\n  0.49944642878988355,\n  0.4916005716002753]}"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"torch.save(model.state_dict(), 'decoder_model.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T14:19:10.394939Z","iopub.execute_input":"2026-02-25T14:19:10.395722Z","iopub.status.idle":"2026-02-25T14:19:10.485355Z","shell.execute_reply.started":"2026-02-25T14:19:10.395693Z","shell.execute_reply":"2026-02-25T14:19:10.484602Z"}},"outputs":[],"execution_count":32},{"cell_type":"markdown","source":"## Pending Improvements \n### Text Generation using autoregressive decoding","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}